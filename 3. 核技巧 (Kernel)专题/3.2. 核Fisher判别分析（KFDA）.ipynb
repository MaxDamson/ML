{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFDA（Kernel Fisher Discriminant Analysis）核Fisher判别分析\n",
    "核Fisher判别分析（Kernel Fisher Discriminant Analysis, KFDA）是一种应用核技巧的监督学习方法，用于模式识别和分类问题。KFDA将数据映射到一个高维特征空间，利用核技巧在该空间中执行线性Fisher判别分析，以实现更好的类别分离。下面详细介绍KFDA的核心思想、优化目标、损失函数、几何意义、关键公式、具体流程以及优缺点。\n",
    "### KFDA的思想：\n",
    "KFDA的思想基于传统的Fisher判别分析（FDA），旨在找到一个线性投影，使得投影后的数据在类间方差最大化，而类内方差最小化。KFDA通过将数据映射到一个高维核空间来实现这一目标，使得在原始空间中非线性可分的数据在新空间中变得线性可分。\n",
    "### 优化目标：\n",
    "KFDA的优化目标是最大化核空间中的类间散度（between-class scatter）与类内散度（within-class scatter）的比率。具体来说，目标是找到一个方向向量，沿此方向投影后，最大化类间散度同时最小化类内散度。\n",
    "### 损失函数及其几何意义：\n",
    "KFDA没有显式的“损失函数”，但其优化可以视为一个损失最小化问题，即最小化类内散度同时最大化类间散度。其几何意义在于通过优化这一准则，确保数据在新的投影空间中能够尽可能地根据类别进行分离，从而提高分类的准确性。\n",
    "### 关键公式：\n",
    "在KFDA中，关键的操作是计算核矩阵 \\(K\\) 并应用它来表述类内散度矩阵 \\(S_W\\) 和类间散度矩阵 \\(S_B\\)：\n",
    "$$\n",
    "S_W = \\sum_{i=1}^{c} \\sum_{x_j \\in C_i} (\\phi(x_j) - m_i)(\\phi(x_j) - m_i)^T\n",
    "$$\n",
    "$$\n",
    "S_B = \\sum_{i=1}^{c} N_i (m_i - m)(m_i - m)^T\n",
    "$$\n",
    "其中，\\( \\phi(x) \\) 表示映射到核空间后的数据点，\\( m_i \\) 和 \\( m \\) 分别是类内和全局平均在核空间的映射，\\( N_i \\) 是第 \\( i \\) 个类的样本数量。\n",
    "### 具体流程：\n",
    "1. **选择核函数**：选择合适的核函数（如高斯核、多项式核等）。\n",
    "2. **构建核矩阵**：计算核矩阵 \\(K\\)。\n",
    "3. **计算散度矩阵**：使用核矩阵来估计 \\(S_W\\) 和 \\(S_B\\)。\n",
    "4. **求解广义特征值问题**：解决 \\(S_W^{-1} S_B\\) 的特征值问题来找到最优投影。\n",
    "5. **降维与分类**：使用得到的投影进行数据降维和后续的分类任务。\n",
    "### 优缺点：\n",
    "**优点**：\n",
    "- **非线性分类能力**：KFDA通过核技术能够处理原始空间中线性不可分的问题。\n",
    "- **有效的类别分离**：通过最大化类间散度和最小化类内散度，提高分类的效果。\n",
    "\n",
    "**缺点**：\n",
    "- **计算成本高**：尤其是在数据集大时，计算和存储核矩阵需要较大的计算资源。\n",
    "- **核函数选择**：核函数的选择关键但往往依赖于经验和实验。\n",
    "- **过拟合风险**：在高维特征空间中，如果参数选择不当，可能会导致过拟合。\n",
    "通过这种方法，KFDA为解决复杂的分类问题提供了一种有效的工具，尤其是在传统的线性方法可能失败的场合。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
