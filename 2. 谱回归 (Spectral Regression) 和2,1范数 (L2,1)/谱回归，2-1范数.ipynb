{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 谱回归\n",
    "\n",
    "谱回归是一种结合了图论和回归分析的方法，旨在处理高维数据时保持数据的局部结构和全局连续性。这种方法利用图的谱理论，尤其是拉普拉斯矩阵的特性，来发现数据中的底层结构，从而进行有效的回归预测。下面是谱回归的详细介绍，包括其思想、优化目标、损失函数及其几何意义、关键公式、具体流程以及优缺点。\n",
    "### 谱回归的思想：\n",
    "谱回归的核心思想是通过构建一个图，其中节点代表数据点，边的权重表示节点之间的相似性。通过考虑这个图的拉普拉斯矩阵，谱回归尝试在回归模型中保持数据点的局部邻近性，使得相似的数据点在回归预测中得到相似的预测值。\n",
    "### 优化目标：\n",
    "谱回归的优化目标是最小化预测误差的同时，确保相邻节点（即在图中相连的点）的预测值相近。这通常通过最小化一个包含拉普拉斯正则项的损失函数来实现，该正则项惩罚图中相邻节点之间预测值的差异。\n",
    "### 损失函数及其几何意义：\n",
    "- **损失函数**形式为：\n",
    "  $$\n",
    "  L(f) = \\|f - y\\|^2 + \\lambda f^T L f\n",
    "  $$\n",
    "  其中，$f$ 是预测函数，$y$ 是真实值，$\\lambda$ 是正则化参数，$L$ 是图的拉普拉斯矩阵。\n",
    "- **几何意义**：第一项$\\|f - y\\|^2$是常规的平方误差，表示预测值和真实值之间的差距。第二项$f^T L f$则确保如果两个数据点在图中相近，则它们的预测值也应该接近。这样，拉普拉斯矩阵的这一特性促进了模型在高维数据中保持局部连续性。\n",
    "### 关键公式：\n",
    "关键的概念是拉普拉斯矩阵 $L$，它是定义在图上的，可以表达为 $L = D - W$，其中$W$是相似性矩阵（权重矩阵），$D$是度矩阵（其对角线元素是相应节点的度）。\n",
    "### 具体流程：\n",
    "1. **图构建**：根据数据点间的相似性构建图，并定义权重矩阵$W$。\n",
    "2. **计算拉普拉斯矩阵**$L$。\n",
    "3. **优化损失函数**：通过求解上述损失函数来训练回归模型。\n",
    "4. **模型评估**：在测试集上评估模型的预测性能。\n",
    "### 优缺点：\n",
    "**优点**：\n",
    "- **保持数据结构**：通过拉普拉斯正则化，模型能够有效保持数据的局部结构，适用于高维和复杂的数据集。\n",
    "- **灵活性**：通过调整正则化参数$\\lambda$，可以平衡拟合误差和结构保持。\n",
    "**缺点**：\n",
    "- **计算成本**：构建图和计算拉普拉斯矩阵可能在大规模数据集上非常昂贵。\n",
    "- **参数选择**：正则化参数$\\lambda$和图的构建（如相似性度量和邻居选择）的选择对模型性能有显著影响。\n",
    "谱回归通过这种独特的结合图论和回归分析的方式，提供了一种处理特别是在非线性和复杂数据结构上的有力工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2-1 范数\n",
    "\n",
    "L2-1范数是在机器学习和优化中使用的一种混合范数，它结合了L2范数（欧几里得范数）和L1范数的特性，常用于稀疏学习和特征选择。L2-1范数特别适用于处理具有组结构的数据，例如，当特征自然分组时（如多任务学习中的不同任务或多通道信号处理）。下面详细介绍L2-1范数的思想、几何意义、关键公式及其优点。\n",
    "### L2-1范数的思想：\n",
    "L2-1范数的核心思想是通过对参数的每个组应用L2范数，然后对所有组的结果应用L1范数，从而实现组间的稀疏性（即选择重要的组）和组内的密集性（组内的参数可以共同非零）。这种范数可以看作是L1范数和L2范数的结合，旨在同时保留组内的关联性和实现组间的稀疏性。\n",
    "### 表达的几何意义：\n",
    "几何上，L2-1范数促使解空间在各个组间表现出角锥形结构，这意味着它倾向于完全消除某些组的贡献（使整个组的系数为零），而保持其他组的系数为非零。这样的结构有利于在保持相关特征集的同时，去除整个无关特征组，特别适用于那些特征之间有内在联系的应用场景。\n",
    "### 关键公式：\n",
    "假设有一个参数矩阵 $ W \\in \\mathbb{R}^{d \\times m} $，其中 $ d $ 是特征的数量，$ m $ 是任务的数量。L2-1范数定义为：\n",
    "$$\n",
    "\\|W\\|_{2,1} = \\sum_{i=1}^d \\sqrt{\\sum_{j=1}^m w_{ij}^2}\n",
    "$$\n",
    "这里，内部的求和（内层的平方和后开方）计算的是第 $ i $ 行参数的L2范数，外部的求和对所有行的L2范数结果应用L1范数，从而促使一些行（即特征）的整体权重向量变为零，实现特征组的选择。\n",
    "### 优点：\n",
    "1. **组间稀疏性**：L2-1范数能够识别并选择最重要的特征组，这对于包含群组结构特征的数据非常有效。\n",
    "2. **组内稳定性**：在组内，L2范数有助于保持特征的稳定性和连续性，即组内的特征被整体选中或排除。\n",
    "3. **降低过拟合风险**：通过减少模型中参与的特征数量，L2-1范数有助于提高模型的泛化能力。\n",
    "4. **提高解释性**：由于它倾向于选择整个特征组，这种范数使模型更易于解释，特别是在多任务学习或相关任务中。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
